{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)= fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1bef616c808>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(x_train[100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(-1,28,28,1)\n",
    "x_test=x_test.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,(3,3),input_shape=x_train.shape[1:], activation = 'relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(32,(3,3),input_shape=x_train.shape[1:], activation = 'relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    " \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                loss = 'sparse_categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 36s 39ms/step - loss: 0.9749 - accuracy: 0.7876 - val_loss: 0.4769 - val_accuracy: 0.8287\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 36s 38ms/step - loss: 0.3872 - accuracy: 0.8640 - val_loss: 0.4088 - val_accuracy: 0.8543\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 37s 39ms/step - loss: 0.3434 - accuracy: 0.8775 - val_loss: 0.3749 - val_accuracy: 0.8658\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 36s 39ms/step - loss: 0.3131 - accuracy: 0.8869 - val_loss: 0.3837 - val_accuracy: 0.8642\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 36s 39ms/step - loss: 0.2918 - accuracy: 0.8938 - val_loss: 0.3577 - val_accuracy: 0.8723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bef6430208>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.fit(x_train, y_train, batch_size = 64, epochs = 5, validation_data= (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_dir = f'{int(time.time())}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_hp(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(hp.Int('input_units',min_value=32,max_value=256, step= 32),\n",
    "                     (3,3),input_shape=x_train.shape[1:], activation = 'relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    for i in range(hp.Int('n_layers',1,4)):\n",
    "        model.add(Conv2D(hp.Int(f'conv_{i}_units',min_value=32,max_value=256, step= 32),\n",
    "                         (3,3),input_shape=x_train.shape[1:], activation = 'relu'))\n",
    "\n",
    "    \n",
    " \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                loss = 'sparse_categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/938 [====>.........................] - ETA: 0s - loss: 17.0711 - accuracy: 0.0000e+0 - ETA: 45s - loss: 13.6109 - accuracy: 0.1016  - ETA: 1:03 - loss: 11.0426 - accuracy: 0.161 - ETA: 1:12 - loss: 9.4423 - accuracy: 0.199 - ETA: 1:15 - loss: 8.2464 - accuracy: 0.21 - ETA: 1:19 - loss: 7.2863 - accuracy: 0.22 - ETA: 1:21 - loss: 6.5548 - accuracy: 0.22 - ETA: 1:22 - loss: 6.0192 - accuracy: 0.24 - ETA: 1:25 - loss: 5.5895 - accuracy: 0.24 - ETA: 1:25 - loss: 5.2124 - accuracy: 0.24 - ETA: 1:27 - loss: 4.8838 - accuracy: 0.25 - ETA: 1:27 - loss: 4.6202 - accuracy: 0.25 - ETA: 1:27 - loss: 4.3718 - accuracy: 0.28 - ETA: 1:28 - loss: 4.2014 - accuracy: 0.28 - ETA: 1:28 - loss: 4.0338 - accuracy: 0.28 - ETA: 1:28 - loss: 3.8800 - accuracy: 0.29 - ETA: 1:28 - loss: 3.7506 - accuracy: 0.30 - ETA: 1:28 - loss: 3.6274 - accuracy: 0.30 - ETA: 1:28 - loss: 3.5050 - accuracy: 0.31 - ETA: 1:28 - loss: 3.4036 - accuracy: 0.32 - ETA: 1:28 - loss: 3.3098 - accuracy: 0.33 - ETA: 1:28 - loss: 3.2174 - accuracy: 0.34 - ETA: 1:28 - loss: 3.1298 - accuracy: 0.35 - ETA: 1:28 - loss: 3.0561 - accuracy: 0.36 - ETA: 1:28 - loss: 2.9906 - accuracy: 0.36 - ETA: 1:28 - loss: 2.9335 - accuracy: 0.37 - ETA: 1:28 - loss: 2.8638 - accuracy: 0.38 - ETA: 1:28 - loss: 2.8047 - accuracy: 0.38 - ETA: 1:28 - loss: 2.7533 - accuracy: 0.39 - ETA: 1:28 - loss: 2.6985 - accuracy: 0.39 - ETA: 1:28 - loss: 2.6431 - accuracy: 0.40 - ETA: 1:28 - loss: 2.5986 - accuracy: 0.41 - ETA: 1:28 - loss: 2.5561 - accuracy: 0.41 - ETA: 1:28 - loss: 2.5222 - accuracy: 0.42 - ETA: 1:28 - loss: 2.4860 - accuracy: 0.42 - ETA: 1:28 - loss: 2.4466 - accuracy: 0.43 - ETA: 1:28 - loss: 2.4059 - accuracy: 0.44 - ETA: 1:27 - loss: 2.3692 - accuracy: 0.44 - ETA: 1:27 - loss: 2.3432 - accuracy: 0.44 - ETA: 1:27 - loss: 2.3145 - accuracy: 0.45 - ETA: 1:27 - loss: 2.2784 - accuracy: 0.45 - ETA: 1:27 - loss: 2.2475 - accuracy: 0.46 - ETA: 1:27 - loss: 2.2204 - accuracy: 0.46 - ETA: 1:27 - loss: 2.1894 - accuracy: 0.46 - ETA: 1:27 - loss: 2.1641 - accuracy: 0.47 - ETA: 1:27 - loss: 2.1357 - accuracy: 0.47 - ETA: 1:27 - loss: 2.1128 - accuracy: 0.48 - ETA: 1:27 - loss: 2.0905 - accuracy: 0.48 - ETA: 1:26 - loss: 2.0680 - accuracy: 0.48 - ETA: 1:26 - loss: 2.0457 - accuracy: 0.49 - ETA: 1:26 - loss: 2.0213 - accuracy: 0.49 - ETA: 1:26 - loss: 1.9984 - accuracy: 0.50 - ETA: 1:26 - loss: 1.9744 - accuracy: 0.50 - ETA: 1:26 - loss: 1.9493 - accuracy: 0.50 - ETA: 1:26 - loss: 1.9239 - accuracy: 0.51 - ETA: 1:26 - loss: 1.9019 - accuracy: 0.51 - ETA: 1:26 - loss: 1.8834 - accuracy: 0.52 - ETA: 1:26 - loss: 1.8649 - accuracy: 0.52 - ETA: 1:26 - loss: 1.8470 - accuracy: 0.52 - ETA: 1:26 - loss: 1.8267 - accuracy: 0.53 - ETA: 1:25 - loss: 1.8085 - accuracy: 0.53 - ETA: 1:25 - loss: 1.7928 - accuracy: 0.53 - ETA: 1:25 - loss: 1.7820 - accuracy: 0.53 - ETA: 1:25 - loss: 1.7700 - accuracy: 0.53 - ETA: 1:25 - loss: 1.7563 - accuracy: 0.54 - ETA: 1:25 - loss: 1.7404 - accuracy: 0.54 - ETA: 1:25 - loss: 1.7272 - accuracy: 0.54 - ETA: 1:25 - loss: 1.7127 - accuracy: 0.55 - ETA: 1:25 - loss: 1.6983 - accuracy: 0.55 - ETA: 1:25 - loss: 1.6835 - accuracy: 0.55 - ETA: 1:25 - loss: 1.6692 - accuracy: 0.55 - ETA: 1:25 - loss: 1.6566 - accuracy: 0.56 - ETA: 1:24 - loss: 1.6419 - accuracy: 0.56 - ETA: 1:24 - loss: 1.6312 - accuracy: 0.56 - ETA: 1:24 - loss: 1.6211 - accuracy: 0.56 - ETA: 1:24 - loss: 1.6093 - accuracy: 0.56 - ETA: 1:24 - loss: 1.5955 - accuracy: 0.57 - ETA: 1:24 - loss: 1.5813 - accuracy: 0.57 - ETA: 1:24 - loss: 1.5694 - accuracy: 0.57 - ETA: 1:24 - loss: 1.5561 - accuracy: 0.58 - ETA: 1:24 - loss: 1.5436 - accuracy: 0.58 - ETA: 1:24 - loss: 1.5343 - accuracy: 0.58 - ETA: 1:24 - loss: 1.5237 - accuracy: 0.58 - ETA: 1:24 - loss: 1.5123 - accuracy: 0.59 - ETA: 1:24 - loss: 1.5038 - accuracy: 0.59 - ETA: 1:24 - loss: 1.4944 - accuracy: 0.59 - ETA: 1:24 - loss: 1.4852 - accuracy: 0.59 - ETA: 1:24 - loss: 1.4749 - accuracy: 0.59 - ETA: 1:24 - loss: 1.4652 - accuracy: 0.59 - ETA: 1:24 - loss: 1.4577 - accuracy: 0.60 - ETA: 1:24 - loss: 1.4503 - accuracy: 0.60 - ETA: 1:24 - loss: 1.4403 - accuracy: 0.60 - ETA: 1:24 - loss: 1.4321 - accuracy: 0.60 - ETA: 1:24 - loss: 1.4236 - accuracy: 0.60 - ETA: 1:24 - loss: 1.4169 - accuracy: 0.60 - ETA: 1:24 - loss: 1.4092 - accuracy: 0.61 - ETA: 1:24 - loss: 1.4005 - accuracy: 0.61 - ETA: 1:24 - loss: 1.3943 - accuracy: 0.61 - ETA: 1:24 - loss: 1.3864 - accuracy: 0.61 - ETA: 1:24 - loss: 1.3774 - accuracy: 0.61 - ETA: 1:24 - loss: 1.3701 - accuracy: 0.61 - ETA: 1:23 - loss: 1.3619 - accuracy: 0.62 - ETA: 1:23 - loss: 1.3552 - accuracy: 0.62 - ETA: 1:23 - loss: 1.3471 - accuracy: 0.62 - ETA: 1:23 - loss: 1.3397 - accuracy: 0.62 - ETA: 1:23 - loss: 1.3344 - accuracy: 0.62 - ETA: 1:23 - loss: 1.3289 - accuracy: 0.62 - ETA: 1:22 - loss: 1.3230 - accuracy: 0.62 - ETA: 1:22 - loss: 1.3173 - accuracy: 0.63 - ETA: 1:23 - loss: 1.3094 - accuracy: 0.63 - ETA: 1:22 - loss: 1.3048 - accuracy: 0.63 - ETA: 1:22 - loss: 1.2995 - accuracy: 0.63 - ETA: 1:22 - loss: 1.2913 - accuracy: 0.63 - ETA: 1:22 - loss: 1.2841 - accuracy: 0.63 - ETA: 1:22 - loss: 1.2770 - accuracy: 0.63 - ETA: 1:22 - loss: 1.2733 - accuracy: 0.63 - ETA: 1:22 - loss: 1.2666 - accuracy: 0.63 - ETA: 1:22 - loss: 1.2623 - accuracy: 0.64 - ETA: 1:22 - loss: 1.2570 - accuracy: 0.64 - ETA: 1:22 - loss: 1.2512 - accuracy: 0.64 - ETA: 1:22 - loss: 1.2461 - accuracy: 0.64 - ETA: 1:22 - loss: 1.2418 - accuracy: 0.64 - ETA: 1:22 - loss: 1.2380 - accuracy: 0.64 - ETA: 1:22 - loss: 1.2318 - accuracy: 0.64 - ETA: 1:22 - loss: 1.2284 - accuracy: 0.64 - ETA: 1:22 - loss: 1.2244 - accuracy: 0.64 - ETA: 1:22 - loss: 1.2189 - accuracy: 0.64 - ETA: 1:22 - loss: 1.2131 - accuracy: 0.65 - ETA: 1:22 - loss: 1.2092 - accuracy: 0.65 - ETA: 1:22 - loss: 1.2048 - accuracy: 0.65 - ETA: 1:22 - loss: 1.2001 - accuracy: 0.65 - ETA: 1:22 - loss: 1.1962 - accuracy: 0.65 - ETA: 1:22 - loss: 1.1924 - accuracy: 0.65 - ETA: 1:22 - loss: 1.1883 - accuracy: 0.65 - ETA: 1:22 - loss: 1.1847 - accuracy: 0.65 - ETA: 1:22 - loss: 1.1812 - accuracy: 0.65 - ETA: 1:22 - loss: 1.1786 - accuracy: 0.65 - ETA: 1:22 - loss: 1.1725 - accuracy: 0.65 - ETA: 1:22 - loss: 1.1691 - accuracy: 0.65 - ETA: 1:22 - loss: 1.1651 - accuracy: 0.66 - ETA: 1:22 - loss: 1.1608 - accuracy: 0.66 - ETA: 1:22 - loss: 1.1572 - accuracy: 0.66 - ETA: 1:22 - loss: 1.1525 - accuracy: 0.66 - ETA: 1:22 - loss: 1.1483 - accuracy: 0.66 - ETA: 1:22 - loss: 1.1448 - accuracy: 0.66 - ETA: 1:22 - loss: 1.1409 - accuracy: 0.66 - ETA: 1:22 - loss: 1.1384 - accuracy: 0.66 - ETA: 1:22 - loss: 1.1342 - accuracy: 0.66 - ETA: 1:22 - loss: 1.1307 - accuracy: 0.66 - ETA: 1:21 - loss: 1.1269 - accuracy: 0.66 - ETA: 1:21 - loss: 1.1225 - accuracy: 0.66 - ETA: 1:21 - loss: 1.1192 - accuracy: 0.66 - ETA: 1:21 - loss: 1.1160 - accuracy: 0.67 - ETA: 1:21 - loss: 1.1117 - accuracy: 0.67 - ETA: 1:21 - loss: 1.1097 - accuracy: 0.67 - ETA: 1:21 - loss: 1.1057 - accuracy: 0.67 - ETA: 1:21 - loss: 1.1010 - accuracy: 0.67 - ETA: 1:21 - loss: 1.0971 - accuracy: 0.67 - ETA: 1:21 - loss: 1.0946 - accuracy: 0.67 - ETA: 1:21 - loss: 1.0912 - accuracy: 0.67 - ETA: 1:21 - loss: 1.0874 - accuracy: 0.67 - ETA: 1:21 - loss: 1.0838 - accuracy: 0.67 - ETA: 1:21 - loss: 1.0802 - accuracy: 0.67 - ETA: 1:21 - loss: 1.0773 - accuracy: 0.67 - ETA: 1:21 - loss: 1.0764 - accuracy: 0.67 - ETA: 1:21 - loss: 1.0746 - accuracy: 0.67 - ETA: 1:21 - loss: 1.0718 - accuracy: 0.67 - ETA: 1:21 - loss: 1.0704 - accuracy: 0.67 - ETA: 1:21 - loss: 1.0673 - accuracy: 0.67 - ETA: 1:21 - loss: 1.0658 - accuracy: 0.68 - ETA: 1:20 - loss: 1.0650 - accuracy: 0.68 - ETA: 1:20 - loss: 1.0620 - accuracy: 0.68 - ETA: 1:20 - loss: 1.0594 - accuracy: 0.68 - ETA: 1:20 - loss: 1.0565 - accuracy: 0.68 - ETA: 1:20 - loss: 1.0523 - accuracy: 0.68 - ETA: 1:20 - loss: 1.0494 - accuracy: 0.68 - ETA: 1:20 - loss: 1.0462 - accuracy: 0.68 - ETA: 1:20 - loss: 1.0437 - accuracy: 0.68 - ETA: 1:20 - loss: 1.0406 - accuracy: 0.68 - ETA: 1:20 - loss: 1.0385 - accuracy: 0.68 - ETA: 1:20 - loss: 1.0374 - accuracy: 0.68 - ETA: 1:20 - loss: 1.0345 - accuracy: 0.68 - ETA: 1:20 - loss: 1.0311 - accuracy: 0.68 - ETA: 1:19 - loss: 1.0292 - accuracy: 0.68 - ETA: 1:19 - loss: 1.0278 - accuracy: 0.68 - ETA: 1:19 - loss: 1.0252 - accuracy: 0.6882"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372/938 [==========>...................] - ETA: 1:19 - loss: 1.0230 - accuracy: 0.68 - ETA: 1:19 - loss: 1.0204 - accuracy: 0.68 - ETA: 1:19 - loss: 1.0184 - accuracy: 0.68 - ETA: 1:19 - loss: 1.0158 - accuracy: 0.69 - ETA: 1:19 - loss: 1.0133 - accuracy: 0.69 - ETA: 1:19 - loss: 1.0100 - accuracy: 0.69 - ETA: 1:19 - loss: 1.0079 - accuracy: 0.69 - ETA: 1:19 - loss: 1.0055 - accuracy: 0.69 - ETA: 1:18 - loss: 1.0026 - accuracy: 0.69 - ETA: 1:18 - loss: 1.0006 - accuracy: 0.69 - ETA: 1:18 - loss: 0.9982 - accuracy: 0.69 - ETA: 1:18 - loss: 0.9955 - accuracy: 0.69 - ETA: 1:18 - loss: 0.9931 - accuracy: 0.69 - ETA: 1:18 - loss: 0.9902 - accuracy: 0.69 - ETA: 1:18 - loss: 0.9871 - accuracy: 0.69 - ETA: 1:18 - loss: 0.9851 - accuracy: 0.69 - ETA: 1:18 - loss: 0.9828 - accuracy: 0.70 - ETA: 1:18 - loss: 0.9806 - accuracy: 0.70 - ETA: 1:18 - loss: 0.9778 - accuracy: 0.70 - ETA: 1:17 - loss: 0.9749 - accuracy: 0.70 - ETA: 1:17 - loss: 0.9726 - accuracy: 0.70 - ETA: 1:17 - loss: 0.9706 - accuracy: 0.70 - ETA: 1:17 - loss: 0.9676 - accuracy: 0.70 - ETA: 1:17 - loss: 0.9668 - accuracy: 0.70 - ETA: 1:17 - loss: 0.9657 - accuracy: 0.70 - ETA: 1:17 - loss: 0.9633 - accuracy: 0.70 - ETA: 1:17 - loss: 0.9614 - accuracy: 0.70 - ETA: 1:17 - loss: 0.9593 - accuracy: 0.70 - ETA: 1:17 - loss: 0.9571 - accuracy: 0.70 - ETA: 1:17 - loss: 0.9559 - accuracy: 0.70 - ETA: 1:16 - loss: 0.9535 - accuracy: 0.70 - ETA: 1:16 - loss: 0.9518 - accuracy: 0.70 - ETA: 1:16 - loss: 0.9501 - accuracy: 0.70 - ETA: 1:16 - loss: 0.9480 - accuracy: 0.70 - ETA: 1:16 - loss: 0.9459 - accuracy: 0.70 - ETA: 1:16 - loss: 0.9451 - accuracy: 0.70 - ETA: 1:16 - loss: 0.9436 - accuracy: 0.70 - ETA: 1:16 - loss: 0.9424 - accuracy: 0.70 - ETA: 1:16 - loss: 0.9410 - accuracy: 0.70 - ETA: 1:15 - loss: 0.9392 - accuracy: 0.71 - ETA: 1:15 - loss: 0.9375 - accuracy: 0.71 - ETA: 1:15 - loss: 0.9358 - accuracy: 0.71 - ETA: 1:15 - loss: 0.9343 - accuracy: 0.71 - ETA: 1:15 - loss: 0.9330 - accuracy: 0.71 - ETA: 1:15 - loss: 0.9313 - accuracy: 0.71 - ETA: 1:15 - loss: 0.9289 - accuracy: 0.71 - ETA: 1:15 - loss: 0.9272 - accuracy: 0.71 - ETA: 1:15 - loss: 0.9259 - accuracy: 0.71 - ETA: 1:14 - loss: 0.9252 - accuracy: 0.71 - ETA: 1:14 - loss: 0.9240 - accuracy: 0.71 - ETA: 1:14 - loss: 0.9220 - accuracy: 0.71 - ETA: 1:14 - loss: 0.9198 - accuracy: 0.71 - ETA: 1:14 - loss: 0.9176 - accuracy: 0.71 - ETA: 1:14 - loss: 0.9155 - accuracy: 0.71 - ETA: 1:14 - loss: 0.9138 - accuracy: 0.71 - ETA: 1:14 - loss: 0.9126 - accuracy: 0.71 - ETA: 1:14 - loss: 0.9109 - accuracy: 0.71 - ETA: 1:14 - loss: 0.9091 - accuracy: 0.71 - ETA: 1:13 - loss: 0.9075 - accuracy: 0.71 - ETA: 1:13 - loss: 0.9061 - accuracy: 0.71 - ETA: 1:13 - loss: 0.9044 - accuracy: 0.71 - ETA: 1:13 - loss: 0.9036 - accuracy: 0.71 - ETA: 1:13 - loss: 0.9019 - accuracy: 0.71 - ETA: 1:13 - loss: 0.9005 - accuracy: 0.71 - ETA: 1:13 - loss: 0.8994 - accuracy: 0.71 - ETA: 1:13 - loss: 0.8977 - accuracy: 0.72 - ETA: 1:13 - loss: 0.8961 - accuracy: 0.72 - ETA: 1:12 - loss: 0.8947 - accuracy: 0.72 - ETA: 1:12 - loss: 0.8931 - accuracy: 0.72 - ETA: 1:12 - loss: 0.8913 - accuracy: 0.72 - ETA: 1:12 - loss: 0.8902 - accuracy: 0.72 - ETA: 1:12 - loss: 0.8890 - accuracy: 0.72 - ETA: 1:12 - loss: 0.8867 - accuracy: 0.72 - ETA: 1:12 - loss: 0.8847 - accuracy: 0.72 - ETA: 1:12 - loss: 0.8835 - accuracy: 0.72 - ETA: 1:12 - loss: 0.8820 - accuracy: 0.72 - ETA: 1:12 - loss: 0.8812 - accuracy: 0.72 - ETA: 1:11 - loss: 0.8796 - accuracy: 0.72 - ETA: 1:11 - loss: 0.8775 - accuracy: 0.72 - ETA: 1:11 - loss: 0.8762 - accuracy: 0.72 - ETA: 1:11 - loss: 0.8768 - accuracy: 0.72 - ETA: 1:11 - loss: 0.8751 - accuracy: 0.72 - ETA: 1:11 - loss: 0.8744 - accuracy: 0.72 - ETA: 1:11 - loss: 0.8732 - accuracy: 0.72 - ETA: 1:11 - loss: 0.8719 - accuracy: 0.72 - ETA: 1:11 - loss: 0.8715 - accuracy: 0.72 - ETA: 1:10 - loss: 0.8702 - accuracy: 0.72 - ETA: 1:10 - loss: 0.8684 - accuracy: 0.72 - ETA: 1:10 - loss: 0.8675 - accuracy: 0.72 - ETA: 1:10 - loss: 0.8663 - accuracy: 0.72 - ETA: 1:10 - loss: 0.8650 - accuracy: 0.72 - ETA: 1:10 - loss: 0.8637 - accuracy: 0.72 - ETA: 1:10 - loss: 0.8629 - accuracy: 0.72 - ETA: 1:10 - loss: 0.8616 - accuracy: 0.72 - ETA: 1:10 - loss: 0.8605 - accuracy: 0.73 - ETA: 1:10 - loss: 0.8603 - accuracy: 0.72 - ETA: 1:09 - loss: 0.8589 - accuracy: 0.73 - ETA: 1:09 - loss: 0.8576 - accuracy: 0.73 - ETA: 1:09 - loss: 0.8569 - accuracy: 0.73 - ETA: 1:09 - loss: 0.8555 - accuracy: 0.73 - ETA: 1:09 - loss: 0.8550 - accuracy: 0.73 - ETA: 1:09 - loss: 0.8536 - accuracy: 0.73 - ETA: 1:09 - loss: 0.8522 - accuracy: 0.73 - ETA: 1:09 - loss: 0.8507 - accuracy: 0.73 - ETA: 1:09 - loss: 0.8492 - accuracy: 0.73 - ETA: 1:09 - loss: 0.8477 - accuracy: 0.73 - ETA: 1:08 - loss: 0.8459 - accuracy: 0.73 - ETA: 1:08 - loss: 0.8445 - accuracy: 0.73 - ETA: 1:08 - loss: 0.8434 - accuracy: 0.73 - ETA: 1:08 - loss: 0.8420 - accuracy: 0.73 - ETA: 1:08 - loss: 0.8407 - accuracy: 0.73 - ETA: 1:08 - loss: 0.8396 - accuracy: 0.73 - ETA: 1:08 - loss: 0.8385 - accuracy: 0.73 - ETA: 1:08 - loss: 0.8371 - accuracy: 0.73 - ETA: 1:08 - loss: 0.8362 - accuracy: 0.73 - ETA: 1:08 - loss: 0.8345 - accuracy: 0.73 - ETA: 1:07 - loss: 0.8330 - accuracy: 0.73 - ETA: 1:07 - loss: 0.8317 - accuracy: 0.73 - ETA: 1:07 - loss: 0.8311 - accuracy: 0.73 - ETA: 1:07 - loss: 0.8309 - accuracy: 0.73 - ETA: 1:07 - loss: 0.8294 - accuracy: 0.73 - ETA: 1:07 - loss: 0.8280 - accuracy: 0.73 - ETA: 1:07 - loss: 0.8270 - accuracy: 0.73 - ETA: 1:07 - loss: 0.8257 - accuracy: 0.73 - ETA: 1:07 - loss: 0.8254 - accuracy: 0.73 - ETA: 1:07 - loss: 0.8245 - accuracy: 0.73 - ETA: 1:06 - loss: 0.8231 - accuracy: 0.73 - ETA: 1:06 - loss: 0.8213 - accuracy: 0.74 - ETA: 1:06 - loss: 0.8203 - accuracy: 0.74 - ETA: 1:06 - loss: 0.8192 - accuracy: 0.74 - ETA: 1:06 - loss: 0.8196 - accuracy: 0.74 - ETA: 1:06 - loss: 0.8193 - accuracy: 0.74 - ETA: 1:06 - loss: 0.8182 - accuracy: 0.74 - ETA: 1:06 - loss: 0.8172 - accuracy: 0.74 - ETA: 1:06 - loss: 0.8176 - accuracy: 0.74 - ETA: 1:06 - loss: 0.8179 - accuracy: 0.74 - ETA: 1:06 - loss: 0.8176 - accuracy: 0.74 - ETA: 1:05 - loss: 0.8165 - accuracy: 0.74 - ETA: 1:05 - loss: 0.8164 - accuracy: 0.74 - ETA: 1:05 - loss: 0.8157 - accuracy: 0.74 - ETA: 1:05 - loss: 0.8149 - accuracy: 0.74 - ETA: 1:05 - loss: 0.8144 - accuracy: 0.74 - ETA: 1:05 - loss: 0.8135 - accuracy: 0.74 - ETA: 1:05 - loss: 0.8130 - accuracy: 0.74 - ETA: 1:05 - loss: 0.8120 - accuracy: 0.74 - ETA: 1:05 - loss: 0.8117 - accuracy: 0.74 - ETA: 1:04 - loss: 0.8104 - accuracy: 0.74 - ETA: 1:04 - loss: 0.8091 - accuracy: 0.74 - ETA: 1:04 - loss: 0.8080 - accuracy: 0.74 - ETA: 1:04 - loss: 0.8070 - accuracy: 0.74 - ETA: 1:04 - loss: 0.8061 - accuracy: 0.74 - ETA: 1:04 - loss: 0.8056 - accuracy: 0.74 - ETA: 1:04 - loss: 0.8045 - accuracy: 0.74 - ETA: 1:04 - loss: 0.8033 - accuracy: 0.74 - ETA: 1:04 - loss: 0.8030 - accuracy: 0.74 - ETA: 1:04 - loss: 0.8022 - accuracy: 0.74 - ETA: 1:03 - loss: 0.8012 - accuracy: 0.74 - ETA: 1:03 - loss: 0.8004 - accuracy: 0.74 - ETA: 1:03 - loss: 0.7998 - accuracy: 0.74 - ETA: 1:03 - loss: 0.7985 - accuracy: 0.74 - ETA: 1:03 - loss: 0.7978 - accuracy: 0.74 - ETA: 1:03 - loss: 0.7964 - accuracy: 0.74 - ETA: 1:03 - loss: 0.7959 - accuracy: 0.74 - ETA: 1:03 - loss: 0.7954 - accuracy: 0.74 - ETA: 1:03 - loss: 0.7945 - accuracy: 0.74 - ETA: 1:02 - loss: 0.7934 - accuracy: 0.74 - ETA: 1:02 - loss: 0.7928 - accuracy: 0.74 - ETA: 1:02 - loss: 0.7916 - accuracy: 0.74 - ETA: 1:02 - loss: 0.7909 - accuracy: 0.74 - ETA: 1:02 - loss: 0.7901 - accuracy: 0.74 - ETA: 1:02 - loss: 0.7896 - accuracy: 0.74 - ETA: 1:02 - loss: 0.7888 - accuracy: 0.74 - ETA: 1:02 - loss: 0.7879 - accuracy: 0.74 - ETA: 1:02 - loss: 0.7865 - accuracy: 0.74 - ETA: 1:01 - loss: 0.7860 - accuracy: 0.74 - ETA: 1:01 - loss: 0.7857 - accuracy: 0.74 - ETA: 1:01 - loss: 0.7850 - accuracy: 0.74 - ETA: 1:01 - loss: 0.7841 - accuracy: 0.74 - ETA: 1:01 - loss: 0.7833 - accuracy: 0.74 - ETA: 1:01 - loss: 0.7822 - accuracy: 0.74 - ETA: 1:01 - loss: 0.7812 - accuracy: 0.74 - ETA: 1:01 - loss: 0.7800 - accuracy: 0.74 - ETA: 1:01 - loss: 0.7791 - accuracy: 0.74 - ETA: 1:00 - loss: 0.7789 - accuracy: 0.74 - ETA: 1:00 - loss: 0.7781 - accuracy: 0.75 - ETA: 1:00 - loss: 0.7782 - accuracy: 0.7501"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/938 [================>.............] - ETA: 1:00 - loss: 0.7776 - accuracy: 0.75 - ETA: 1:00 - loss: 0.7771 - accuracy: 0.75 - ETA: 1:00 - loss: 0.7759 - accuracy: 0.75 - ETA: 1:00 - loss: 0.7750 - accuracy: 0.75 - ETA: 1:00 - loss: 0.7741 - accuracy: 0.75 - ETA: 1:00 - loss: 0.7731 - accuracy: 0.75 - ETA: 1:00 - loss: 0.7724 - accuracy: 0.75 - ETA: 59s - loss: 0.7719 - accuracy: 0.7519 - ETA: 59s - loss: 0.7713 - accuracy: 0.751 - ETA: 59s - loss: 0.7702 - accuracy: 0.752 - ETA: 59s - loss: 0.7694 - accuracy: 0.752 - ETA: 59s - loss: 0.7692 - accuracy: 0.752 - ETA: 59s - loss: 0.7681 - accuracy: 0.752 - ETA: 59s - loss: 0.7675 - accuracy: 0.752 - ETA: 59s - loss: 0.7664 - accuracy: 0.753 - ETA: 59s - loss: 0.7654 - accuracy: 0.753 - ETA: 58s - loss: 0.7647 - accuracy: 0.753 - ETA: 58s - loss: 0.7636 - accuracy: 0.753 - ETA: 58s - loss: 0.7623 - accuracy: 0.754 - ETA: 58s - loss: 0.7612 - accuracy: 0.754 - ETA: 58s - loss: 0.7605 - accuracy: 0.754 - ETA: 58s - loss: 0.7599 - accuracy: 0.754 - ETA: 58s - loss: 0.7588 - accuracy: 0.755 - ETA: 58s - loss: 0.7581 - accuracy: 0.755 - ETA: 58s - loss: 0.7577 - accuracy: 0.755 - ETA: 57s - loss: 0.7566 - accuracy: 0.755 - ETA: 57s - loss: 0.7563 - accuracy: 0.755 - ETA: 57s - loss: 0.7551 - accuracy: 0.756 - ETA: 57s - loss: 0.7537 - accuracy: 0.756 - ETA: 57s - loss: 0.7528 - accuracy: 0.756 - ETA: 57s - loss: 0.7517 - accuracy: 0.757 - ETA: 57s - loss: 0.7513 - accuracy: 0.757 - ETA: 57s - loss: 0.7508 - accuracy: 0.757 - ETA: 57s - loss: 0.7499 - accuracy: 0.757 - ETA: 56s - loss: 0.7493 - accuracy: 0.757 - ETA: 56s - loss: 0.7483 - accuracy: 0.758 - ETA: 56s - loss: 0.7475 - accuracy: 0.758 - ETA: 56s - loss: 0.7468 - accuracy: 0.758 - ETA: 56s - loss: 0.7461 - accuracy: 0.758 - ETA: 56s - loss: 0.7453 - accuracy: 0.758 - ETA: 56s - loss: 0.7444 - accuracy: 0.759 - ETA: 56s - loss: 0.7440 - accuracy: 0.759 - ETA: 56s - loss: 0.7434 - accuracy: 0.759 - ETA: 56s - loss: 0.7427 - accuracy: 0.759 - ETA: 55s - loss: 0.7421 - accuracy: 0.759 - ETA: 55s - loss: 0.7413 - accuracy: 0.759 - ETA: 55s - loss: 0.7408 - accuracy: 0.760 - ETA: 55s - loss: 0.7401 - accuracy: 0.760 - ETA: 55s - loss: 0.7394 - accuracy: 0.760 - ETA: 55s - loss: 0.7390 - accuracy: 0.760 - ETA: 55s - loss: 0.7379 - accuracy: 0.760 - ETA: 55s - loss: 0.7367 - accuracy: 0.761 - ETA: 55s - loss: 0.7362 - accuracy: 0.761 - ETA: 54s - loss: 0.7352 - accuracy: 0.761 - ETA: 54s - loss: 0.7346 - accuracy: 0.761 - ETA: 54s - loss: 0.7339 - accuracy: 0.762 - ETA: 54s - loss: 0.7336 - accuracy: 0.762 - ETA: 54s - loss: 0.7329 - accuracy: 0.762 - ETA: 54s - loss: 0.7324 - accuracy: 0.762 - ETA: 54s - loss: 0.7317 - accuracy: 0.762 - ETA: 54s - loss: 0.7310 - accuracy: 0.762 - ETA: 54s - loss: 0.7303 - accuracy: 0.762 - ETA: 54s - loss: 0.7294 - accuracy: 0.763 - ETA: 53s - loss: 0.7288 - accuracy: 0.763 - ETA: 53s - loss: 0.7279 - accuracy: 0.763 - ETA: 53s - loss: 0.7269 - accuracy: 0.763 - ETA: 53s - loss: 0.7262 - accuracy: 0.764 - ETA: 53s - loss: 0.7252 - accuracy: 0.764 - ETA: 53s - loss: 0.7243 - accuracy: 0.764 - ETA: 53s - loss: 0.7242 - accuracy: 0.764 - ETA: 53s - loss: 0.7233 - accuracy: 0.764 - ETA: 53s - loss: 0.7226 - accuracy: 0.765 - ETA: 52s - loss: 0.7227 - accuracy: 0.765 - ETA: 52s - loss: 0.7222 - accuracy: 0.765 - ETA: 52s - loss: 0.7218 - accuracy: 0.765 - ETA: 52s - loss: 0.7214 - accuracy: 0.765 - ETA: 52s - loss: 0.7210 - accuracy: 0.765 - ETA: 52s - loss: 0.7202 - accuracy: 0.765 - ETA: 52s - loss: 0.7198 - accuracy: 0.765 - ETA: 52s - loss: 0.7191 - accuracy: 0.766 - ETA: 52s - loss: 0.7183 - accuracy: 0.766 - ETA: 51s - loss: 0.7177 - accuracy: 0.766 - ETA: 51s - loss: 0.7168 - accuracy: 0.766 - ETA: 51s - loss: 0.7163 - accuracy: 0.766 - ETA: 51s - loss: 0.7157 - accuracy: 0.766 - ETA: 51s - loss: 0.7155 - accuracy: 0.766 - ETA: 51s - loss: 0.7146 - accuracy: 0.767 - ETA: 51s - loss: 0.7147 - accuracy: 0.767 - ETA: 51s - loss: 0.7141 - accuracy: 0.767 - ETA: 51s - loss: 0.7133 - accuracy: 0.767 - ETA: 51s - loss: 0.7128 - accuracy: 0.767 - ETA: 50s - loss: 0.7122 - accuracy: 0.767 - ETA: 50s - loss: 0.7113 - accuracy: 0.767 - ETA: 50s - loss: 0.7110 - accuracy: 0.768 - ETA: 50s - loss: 0.7104 - accuracy: 0.768 - ETA: 50s - loss: 0.7103 - accuracy: 0.768 - ETA: 50s - loss: 0.7099 - accuracy: 0.768 - ETA: 50s - loss: 0.7094 - accuracy: 0.768 - ETA: 50s - loss: 0.7091 - accuracy: 0.768 - ETA: 50s - loss: 0.7085 - accuracy: 0.768 - ETA: 49s - loss: 0.7088 - accuracy: 0.768 - ETA: 49s - loss: 0.7085 - accuracy: 0.768 - ETA: 49s - loss: 0.7084 - accuracy: 0.768 - ETA: 49s - loss: 0.7078 - accuracy: 0.769 - ETA: 49s - loss: 0.7074 - accuracy: 0.769 - ETA: 49s - loss: 0.7069 - accuracy: 0.769 - ETA: 49s - loss: 0.7066 - accuracy: 0.769 - ETA: 49s - loss: 0.7065 - accuracy: 0.769 - ETA: 49s - loss: 0.7060 - accuracy: 0.769 - ETA: 49s - loss: 0.7053 - accuracy: 0.769 - ETA: 48s - loss: 0.7050 - accuracy: 0.769 - ETA: 48s - loss: 0.7044 - accuracy: 0.769 - ETA: 48s - loss: 0.7037 - accuracy: 0.770 - ETA: 48s - loss: 0.7036 - accuracy: 0.770 - ETA: 48s - loss: 0.7031 - accuracy: 0.770 - ETA: 48s - loss: 0.7024 - accuracy: 0.770 - ETA: 48s - loss: 0.7021 - accuracy: 0.770 - ETA: 48s - loss: 0.7016 - accuracy: 0.770 - ETA: 48s - loss: 0.7009 - accuracy: 0.770 - ETA: 47s - loss: 0.7002 - accuracy: 0.770 - ETA: 47s - loss: 0.6998 - accuracy: 0.770 - ETA: 47s - loss: 0.6994 - accuracy: 0.771 - ETA: 47s - loss: 0.6994 - accuracy: 0.771 - ETA: 47s - loss: 0.6990 - accuracy: 0.771 - ETA: 47s - loss: 0.6984 - accuracy: 0.771 - ETA: 47s - loss: 0.6977 - accuracy: 0.771 - ETA: 47s - loss: 0.6969 - accuracy: 0.771 - ETA: 47s - loss: 0.6963 - accuracy: 0.772 - ETA: 46s - loss: 0.6958 - accuracy: 0.772 - ETA: 46s - loss: 0.6951 - accuracy: 0.772 - ETA: 46s - loss: 0.6945 - accuracy: 0.772 - ETA: 46s - loss: 0.6941 - accuracy: 0.772 - ETA: 46s - loss: 0.6935 - accuracy: 0.772 - ETA: 46s - loss: 0.6931 - accuracy: 0.772 - ETA: 46s - loss: 0.6924 - accuracy: 0.772 - ETA: 46s - loss: 0.6919 - accuracy: 0.772 - ETA: 46s - loss: 0.6912 - accuracy: 0.773 - ETA: 45s - loss: 0.6905 - accuracy: 0.773 - ETA: 45s - loss: 0.6903 - accuracy: 0.773 - ETA: 45s - loss: 0.6899 - accuracy: 0.773 - ETA: 45s - loss: 0.6890 - accuracy: 0.773 - ETA: 45s - loss: 0.6884 - accuracy: 0.773 - ETA: 45s - loss: 0.6878 - accuracy: 0.774 - ETA: 45s - loss: 0.6872 - accuracy: 0.774 - ETA: 45s - loss: 0.6868 - accuracy: 0.774 - ETA: 45s - loss: 0.6862 - accuracy: 0.774 - ETA: 45s - loss: 0.6856 - accuracy: 0.774 - ETA: 44s - loss: 0.6850 - accuracy: 0.774 - ETA: 44s - loss: 0.6843 - accuracy: 0.775 - ETA: 44s - loss: 0.6839 - accuracy: 0.775 - ETA: 44s - loss: 0.6835 - accuracy: 0.775 - ETA: 44s - loss: 0.6831 - accuracy: 0.775 - ETA: 44s - loss: 0.6829 - accuracy: 0.775 - ETA: 44s - loss: 0.6823 - accuracy: 0.775 - ETA: 44s - loss: 0.6815 - accuracy: 0.776 - ETA: 44s - loss: 0.6813 - accuracy: 0.776 - ETA: 43s - loss: 0.6808 - accuracy: 0.776 - ETA: 43s - loss: 0.6804 - accuracy: 0.776 - ETA: 43s - loss: 0.6801 - accuracy: 0.776 - ETA: 43s - loss: 0.6798 - accuracy: 0.776 - ETA: 43s - loss: 0.6794 - accuracy: 0.776 - ETA: 43s - loss: 0.6792 - accuracy: 0.776 - ETA: 43s - loss: 0.6788 - accuracy: 0.776 - ETA: 43s - loss: 0.6784 - accuracy: 0.777 - ETA: 43s - loss: 0.6782 - accuracy: 0.777 - ETA: 43s - loss: 0.6777 - accuracy: 0.777 - ETA: 42s - loss: 0.6776 - accuracy: 0.777 - ETA: 42s - loss: 0.6772 - accuracy: 0.777 - ETA: 42s - loss: 0.6768 - accuracy: 0.777 - ETA: 42s - loss: 0.6765 - accuracy: 0.777 - ETA: 42s - loss: 0.6760 - accuracy: 0.777 - ETA: 42s - loss: 0.6754 - accuracy: 0.777 - ETA: 42s - loss: 0.6748 - accuracy: 0.777 - ETA: 42s - loss: 0.6744 - accuracy: 0.778 - ETA: 42s - loss: 0.6739 - accuracy: 0.778 - ETA: 41s - loss: 0.6734 - accuracy: 0.778 - ETA: 41s - loss: 0.6730 - accuracy: 0.778 - ETA: 41s - loss: 0.6724 - accuracy: 0.778 - ETA: 41s - loss: 0.6722 - accuracy: 0.778 - ETA: 41s - loss: 0.6715 - accuracy: 0.778 - ETA: 41s - loss: 0.6711 - accuracy: 0.779 - ETA: 41s - loss: 0.6704 - accuracy: 0.779 - ETA: 41s - loss: 0.6702 - accuracy: 0.779 - ETA: 41s - loss: 0.6696 - accuracy: 0.779 - ETA: 40s - loss: 0.6693 - accuracy: 0.779 - ETA: 40s - loss: 0.6688 - accuracy: 0.7797"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/938 [======================>.......] - ETA: 40s - loss: 0.6680 - accuracy: 0.780 - ETA: 40s - loss: 0.6676 - accuracy: 0.780 - ETA: 40s - loss: 0.6672 - accuracy: 0.780 - ETA: 40s - loss: 0.6667 - accuracy: 0.780 - ETA: 40s - loss: 0.6665 - accuracy: 0.780 - ETA: 40s - loss: 0.6663 - accuracy: 0.780 - ETA: 40s - loss: 0.6660 - accuracy: 0.780 - ETA: 40s - loss: 0.6655 - accuracy: 0.780 - ETA: 39s - loss: 0.6649 - accuracy: 0.780 - ETA: 39s - loss: 0.6644 - accuracy: 0.780 - ETA: 39s - loss: 0.6642 - accuracy: 0.780 - ETA: 39s - loss: 0.6637 - accuracy: 0.780 - ETA: 39s - loss: 0.6634 - accuracy: 0.781 - ETA: 39s - loss: 0.6631 - accuracy: 0.781 - ETA: 39s - loss: 0.6626 - accuracy: 0.781 - ETA: 39s - loss: 0.6626 - accuracy: 0.781 - ETA: 39s - loss: 0.6621 - accuracy: 0.781 - ETA: 38s - loss: 0.6616 - accuracy: 0.781 - ETA: 38s - loss: 0.6611 - accuracy: 0.781 - ETA: 38s - loss: 0.6605 - accuracy: 0.781 - ETA: 38s - loss: 0.6598 - accuracy: 0.781 - ETA: 38s - loss: 0.6596 - accuracy: 0.781 - ETA: 38s - loss: 0.6593 - accuracy: 0.782 - ETA: 38s - loss: 0.6589 - accuracy: 0.782 - ETA: 38s - loss: 0.6587 - accuracy: 0.782 - ETA: 38s - loss: 0.6582 - accuracy: 0.782 - ETA: 37s - loss: 0.6580 - accuracy: 0.782 - ETA: 37s - loss: 0.6576 - accuracy: 0.782 - ETA: 37s - loss: 0.6571 - accuracy: 0.782 - ETA: 37s - loss: 0.6569 - accuracy: 0.782 - ETA: 37s - loss: 0.6562 - accuracy: 0.782 - ETA: 37s - loss: 0.6559 - accuracy: 0.782 - ETA: 37s - loss: 0.6555 - accuracy: 0.783 - ETA: 37s - loss: 0.6550 - accuracy: 0.783 - ETA: 37s - loss: 0.6545 - accuracy: 0.783 - ETA: 37s - loss: 0.6538 - accuracy: 0.783 - ETA: 36s - loss: 0.6535 - accuracy: 0.783 - ETA: 36s - loss: 0.6531 - accuracy: 0.783 - ETA: 36s - loss: 0.6529 - accuracy: 0.783 - ETA: 36s - loss: 0.6526 - accuracy: 0.783 - ETA: 36s - loss: 0.6519 - accuracy: 0.784 - ETA: 36s - loss: 0.6521 - accuracy: 0.784 - ETA: 36s - loss: 0.6517 - accuracy: 0.784 - ETA: 36s - loss: 0.6513 - accuracy: 0.784 - ETA: 36s - loss: 0.6512 - accuracy: 0.784 - ETA: 35s - loss: 0.6509 - accuracy: 0.784 - ETA: 35s - loss: 0.6505 - accuracy: 0.784 - ETA: 35s - loss: 0.6499 - accuracy: 0.784 - ETA: 35s - loss: 0.6495 - accuracy: 0.784 - ETA: 35s - loss: 0.6491 - accuracy: 0.784 - ETA: 35s - loss: 0.6485 - accuracy: 0.785 - ETA: 35s - loss: 0.6480 - accuracy: 0.785 - ETA: 35s - loss: 0.6478 - accuracy: 0.785 - ETA: 35s - loss: 0.6474 - accuracy: 0.785 - ETA: 34s - loss: 0.6470 - accuracy: 0.785 - ETA: 34s - loss: 0.6467 - accuracy: 0.785 - ETA: 34s - loss: 0.6462 - accuracy: 0.785 - ETA: 34s - loss: 0.6459 - accuracy: 0.785 - ETA: 34s - loss: 0.6459 - accuracy: 0.785 - ETA: 34s - loss: 0.6457 - accuracy: 0.785 - ETA: 34s - loss: 0.6453 - accuracy: 0.785 - ETA: 34s - loss: 0.6451 - accuracy: 0.786 - ETA: 34s - loss: 0.6447 - accuracy: 0.786 - ETA: 34s - loss: 0.6442 - accuracy: 0.786 - ETA: 33s - loss: 0.6441 - accuracy: 0.786 - ETA: 33s - loss: 0.6438 - accuracy: 0.786 - ETA: 33s - loss: 0.6434 - accuracy: 0.786 - ETA: 33s - loss: 0.6430 - accuracy: 0.786 - ETA: 33s - loss: 0.6427 - accuracy: 0.786 - ETA: 33s - loss: 0.6421 - accuracy: 0.786 - ETA: 33s - loss: 0.6416 - accuracy: 0.786 - ETA: 33s - loss: 0.6410 - accuracy: 0.787 - ETA: 33s - loss: 0.6409 - accuracy: 0.787 - ETA: 32s - loss: 0.6408 - accuracy: 0.787 - ETA: 32s - loss: 0.6405 - accuracy: 0.787 - ETA: 32s - loss: 0.6402 - accuracy: 0.787 - ETA: 32s - loss: 0.6397 - accuracy: 0.787 - ETA: 32s - loss: 0.6392 - accuracy: 0.787 - ETA: 32s - loss: 0.6385 - accuracy: 0.787 - ETA: 32s - loss: 0.6380 - accuracy: 0.787 - ETA: 32s - loss: 0.6377 - accuracy: 0.788 - ETA: 32s - loss: 0.6371 - accuracy: 0.788 - ETA: 31s - loss: 0.6368 - accuracy: 0.788 - ETA: 31s - loss: 0.6364 - accuracy: 0.788 - ETA: 31s - loss: 0.6359 - accuracy: 0.788 - ETA: 31s - loss: 0.6357 - accuracy: 0.788 - ETA: 31s - loss: 0.6355 - accuracy: 0.788 - ETA: 31s - loss: 0.6352 - accuracy: 0.788 - ETA: 31s - loss: 0.6347 - accuracy: 0.789 - ETA: 31s - loss: 0.6344 - accuracy: 0.789 - ETA: 31s - loss: 0.6338 - accuracy: 0.789 - ETA: 31s - loss: 0.6333 - accuracy: 0.789 - ETA: 30s - loss: 0.6329 - accuracy: 0.789 - ETA: 30s - loss: 0.6323 - accuracy: 0.789 - ETA: 30s - loss: 0.6319 - accuracy: 0.789 - ETA: 30s - loss: 0.6315 - accuracy: 0.789 - ETA: 30s - loss: 0.6310 - accuracy: 0.790 - ETA: 30s - loss: 0.6309 - accuracy: 0.790 - ETA: 30s - loss: 0.6306 - accuracy: 0.790 - ETA: 30s - loss: 0.6302 - accuracy: 0.790 - ETA: 30s - loss: 0.6300 - accuracy: 0.790 - ETA: 29s - loss: 0.6293 - accuracy: 0.790 - ETA: 29s - loss: 0.6290 - accuracy: 0.790 - ETA: 29s - loss: 0.6285 - accuracy: 0.790 - ETA: 29s - loss: 0.6282 - accuracy: 0.790 - ETA: 29s - loss: 0.6277 - accuracy: 0.791 - ETA: 29s - loss: 0.6275 - accuracy: 0.791 - ETA: 29s - loss: 0.6274 - accuracy: 0.791 - ETA: 29s - loss: 0.6272 - accuracy: 0.791 - ETA: 29s - loss: 0.6268 - accuracy: 0.791 - ETA: 28s - loss: 0.6265 - accuracy: 0.791 - ETA: 28s - loss: 0.6263 - accuracy: 0.791 - ETA: 28s - loss: 0.6259 - accuracy: 0.791 - ETA: 28s - loss: 0.6256 - accuracy: 0.791 - ETA: 28s - loss: 0.6251 - accuracy: 0.791 - ETA: 28s - loss: 0.6247 - accuracy: 0.791 - ETA: 28s - loss: 0.6244 - accuracy: 0.791 - ETA: 28s - loss: 0.6242 - accuracy: 0.792 - ETA: 28s - loss: 0.6240 - accuracy: 0.792 - ETA: 27s - loss: 0.6236 - accuracy: 0.792 - ETA: 27s - loss: 0.6237 - accuracy: 0.792 - ETA: 27s - loss: 0.6234 - accuracy: 0.792 - ETA: 27s - loss: 0.6229 - accuracy: 0.792 - ETA: 27s - loss: 0.6225 - accuracy: 0.792 - ETA: 27s - loss: 0.6224 - accuracy: 0.792 - ETA: 27s - loss: 0.6219 - accuracy: 0.792 - ETA: 27s - loss: 0.6217 - accuracy: 0.792 - ETA: 27s - loss: 0.6214 - accuracy: 0.792 - ETA: 27s - loss: 0.6209 - accuracy: 0.792 - ETA: 26s - loss: 0.6205 - accuracy: 0.792 - ETA: 26s - loss: 0.6201 - accuracy: 0.792 - ETA: 26s - loss: 0.6199 - accuracy: 0.793 - ETA: 26s - loss: 0.6196 - accuracy: 0.793 - ETA: 26s - loss: 0.6192 - accuracy: 0.793 - ETA: 26s - loss: 0.6187 - accuracy: 0.793 - ETA: 26s - loss: 0.6182 - accuracy: 0.793 - ETA: 26s - loss: 0.6182 - accuracy: 0.793 - ETA: 26s - loss: 0.6178 - accuracy: 0.793 - ETA: 25s - loss: 0.6174 - accuracy: 0.793 - ETA: 25s - loss: 0.6171 - accuracy: 0.793 - ETA: 25s - loss: 0.6169 - accuracy: 0.793 - ETA: 25s - loss: 0.6166 - accuracy: 0.793 - ETA: 25s - loss: 0.6164 - accuracy: 0.794 - ETA: 25s - loss: 0.6159 - accuracy: 0.794 - ETA: 25s - loss: 0.6155 - accuracy: 0.794 - ETA: 25s - loss: 0.6151 - accuracy: 0.794 - ETA: 25s - loss: 0.6150 - accuracy: 0.794 - ETA: 24s - loss: 0.6147 - accuracy: 0.794 - ETA: 24s - loss: 0.6142 - accuracy: 0.794 - ETA: 24s - loss: 0.6140 - accuracy: 0.794 - ETA: 24s - loss: 0.6139 - accuracy: 0.794 - ETA: 24s - loss: 0.6134 - accuracy: 0.794 - ETA: 24s - loss: 0.6132 - accuracy: 0.794 - ETA: 24s - loss: 0.6127 - accuracy: 0.795 - ETA: 24s - loss: 0.6125 - accuracy: 0.795 - ETA: 24s - loss: 0.6125 - accuracy: 0.795 - ETA: 24s - loss: 0.6126 - accuracy: 0.795 - ETA: 23s - loss: 0.6122 - accuracy: 0.795 - ETA: 23s - loss: 0.6120 - accuracy: 0.795 - ETA: 23s - loss: 0.6116 - accuracy: 0.795 - ETA: 23s - loss: 0.6116 - accuracy: 0.795 - ETA: 23s - loss: 0.6112 - accuracy: 0.795 - ETA: 23s - loss: 0.6110 - accuracy: 0.795 - ETA: 23s - loss: 0.6109 - accuracy: 0.795 - ETA: 23s - loss: 0.6104 - accuracy: 0.795 - ETA: 23s - loss: 0.6100 - accuracy: 0.795 - ETA: 22s - loss: 0.6097 - accuracy: 0.796 - ETA: 22s - loss: 0.6093 - accuracy: 0.796 - ETA: 22s - loss: 0.6089 - accuracy: 0.796 - ETA: 22s - loss: 0.6084 - accuracy: 0.796 - ETA: 22s - loss: 0.6081 - accuracy: 0.796 - ETA: 22s - loss: 0.6076 - accuracy: 0.796 - ETA: 22s - loss: 0.6071 - accuracy: 0.796 - ETA: 22s - loss: 0.6067 - accuracy: 0.796 - ETA: 22s - loss: 0.6063 - accuracy: 0.796 - ETA: 21s - loss: 0.6060 - accuracy: 0.797 - ETA: 21s - loss: 0.6057 - accuracy: 0.797 - ETA: 21s - loss: 0.6056 - accuracy: 0.797 - ETA: 21s - loss: 0.6057 - accuracy: 0.797 - ETA: 21s - loss: 0.6055 - accuracy: 0.797 - ETA: 21s - loss: 0.6051 - accuracy: 0.797 - ETA: 21s - loss: 0.6050 - accuracy: 0.797 - ETA: 21s - loss: 0.6044 - accuracy: 0.797 - ETA: 21s - loss: 0.6042 - accuracy: 0.797 - ETA: 21s - loss: 0.6040 - accuracy: 0.797 - ETA: 20s - loss: 0.6037 - accuracy: 0.7979"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934/938 [============================>.] - ETA: 20s - loss: 0.6033 - accuracy: 0.798 - ETA: 20s - loss: 0.6032 - accuracy: 0.798 - ETA: 20s - loss: 0.6028 - accuracy: 0.798 - ETA: 20s - loss: 0.6026 - accuracy: 0.798 - ETA: 20s - loss: 0.6023 - accuracy: 0.798 - ETA: 20s - loss: 0.6019 - accuracy: 0.798 - ETA: 20s - loss: 0.6016 - accuracy: 0.798 - ETA: 20s - loss: 0.6014 - accuracy: 0.798 - ETA: 19s - loss: 0.6010 - accuracy: 0.798 - ETA: 19s - loss: 0.6010 - accuracy: 0.798 - ETA: 19s - loss: 0.6006 - accuracy: 0.798 - ETA: 19s - loss: 0.6003 - accuracy: 0.799 - ETA: 19s - loss: 0.5999 - accuracy: 0.799 - ETA: 19s - loss: 0.5995 - accuracy: 0.799 - ETA: 19s - loss: 0.5994 - accuracy: 0.799 - ETA: 19s - loss: 0.5991 - accuracy: 0.799 - ETA: 19s - loss: 0.5990 - accuracy: 0.799 - ETA: 18s - loss: 0.5988 - accuracy: 0.799 - ETA: 18s - loss: 0.5986 - accuracy: 0.799 - ETA: 18s - loss: 0.5983 - accuracy: 0.799 - ETA: 18s - loss: 0.5979 - accuracy: 0.799 - ETA: 18s - loss: 0.5975 - accuracy: 0.799 - ETA: 18s - loss: 0.5971 - accuracy: 0.800 - ETA: 18s - loss: 0.5970 - accuracy: 0.799 - ETA: 18s - loss: 0.5966 - accuracy: 0.800 - ETA: 18s - loss: 0.5961 - accuracy: 0.800 - ETA: 18s - loss: 0.5960 - accuracy: 0.800 - ETA: 17s - loss: 0.5961 - accuracy: 0.800 - ETA: 17s - loss: 0.5959 - accuracy: 0.800 - ETA: 17s - loss: 0.5955 - accuracy: 0.800 - ETA: 17s - loss: 0.5953 - accuracy: 0.800 - ETA: 17s - loss: 0.5949 - accuracy: 0.800 - ETA: 17s - loss: 0.5947 - accuracy: 0.800 - ETA: 17s - loss: 0.5943 - accuracy: 0.800 - ETA: 17s - loss: 0.5942 - accuracy: 0.800 - ETA: 17s - loss: 0.5938 - accuracy: 0.800 - ETA: 16s - loss: 0.5935 - accuracy: 0.800 - ETA: 16s - loss: 0.5931 - accuracy: 0.801 - ETA: 16s - loss: 0.5930 - accuracy: 0.801 - ETA: 16s - loss: 0.5928 - accuracy: 0.801 - ETA: 16s - loss: 0.5924 - accuracy: 0.801 - ETA: 16s - loss: 0.5922 - accuracy: 0.801 - ETA: 16s - loss: 0.5919 - accuracy: 0.801 - ETA: 16s - loss: 0.5917 - accuracy: 0.801 - ETA: 16s - loss: 0.5914 - accuracy: 0.801 - ETA: 15s - loss: 0.5912 - accuracy: 0.801 - ETA: 15s - loss: 0.5910 - accuracy: 0.801 - ETA: 15s - loss: 0.5908 - accuracy: 0.801 - ETA: 15s - loss: 0.5905 - accuracy: 0.801 - ETA: 15s - loss: 0.5901 - accuracy: 0.801 - ETA: 15s - loss: 0.5897 - accuracy: 0.801 - ETA: 15s - loss: 0.5895 - accuracy: 0.801 - ETA: 15s - loss: 0.5894 - accuracy: 0.801 - ETA: 15s - loss: 0.5891 - accuracy: 0.801 - ETA: 14s - loss: 0.5888 - accuracy: 0.801 - ETA: 14s - loss: 0.5887 - accuracy: 0.802 - ETA: 14s - loss: 0.5885 - accuracy: 0.802 - ETA: 14s - loss: 0.5882 - accuracy: 0.802 - ETA: 14s - loss: 0.5881 - accuracy: 0.802 - ETA: 14s - loss: 0.5877 - accuracy: 0.802 - ETA: 14s - loss: 0.5875 - accuracy: 0.802 - ETA: 14s - loss: 0.5873 - accuracy: 0.802 - ETA: 14s - loss: 0.5872 - accuracy: 0.802 - ETA: 14s - loss: 0.5868 - accuracy: 0.802 - ETA: 13s - loss: 0.5865 - accuracy: 0.802 - ETA: 13s - loss: 0.5861 - accuracy: 0.802 - ETA: 13s - loss: 0.5859 - accuracy: 0.802 - ETA: 13s - loss: 0.5855 - accuracy: 0.802 - ETA: 13s - loss: 0.5852 - accuracy: 0.803 - ETA: 13s - loss: 0.5849 - accuracy: 0.803 - ETA: 13s - loss: 0.5849 - accuracy: 0.803 - ETA: 13s - loss: 0.5847 - accuracy: 0.803 - ETA: 13s - loss: 0.5843 - accuracy: 0.803 - ETA: 12s - loss: 0.5841 - accuracy: 0.803 - ETA: 12s - loss: 0.5840 - accuracy: 0.803 - ETA: 12s - loss: 0.5838 - accuracy: 0.803 - ETA: 12s - loss: 0.5835 - accuracy: 0.803 - ETA: 12s - loss: 0.5834 - accuracy: 0.803 - ETA: 12s - loss: 0.5832 - accuracy: 0.803 - ETA: 12s - loss: 0.5829 - accuracy: 0.803 - ETA: 12s - loss: 0.5827 - accuracy: 0.803 - ETA: 12s - loss: 0.5824 - accuracy: 0.803 - ETA: 11s - loss: 0.5819 - accuracy: 0.803 - ETA: 11s - loss: 0.5819 - accuracy: 0.803 - ETA: 11s - loss: 0.5816 - accuracy: 0.803 - ETA: 11s - loss: 0.5812 - accuracy: 0.804 - ETA: 11s - loss: 0.5811 - accuracy: 0.804 - ETA: 11s - loss: 0.5809 - accuracy: 0.804 - ETA: 11s - loss: 0.5806 - accuracy: 0.804 - ETA: 11s - loss: 0.5804 - accuracy: 0.804 - ETA: 11s - loss: 0.5801 - accuracy: 0.804 - ETA: 10s - loss: 0.5797 - accuracy: 0.804 - ETA: 10s - loss: 0.5795 - accuracy: 0.804 - ETA: 10s - loss: 0.5791 - accuracy: 0.804 - ETA: 10s - loss: 0.5790 - accuracy: 0.804 - ETA: 10s - loss: 0.5788 - accuracy: 0.804 - ETA: 10s - loss: 0.5783 - accuracy: 0.804 - ETA: 10s - loss: 0.5781 - accuracy: 0.804 - ETA: 10s - loss: 0.5777 - accuracy: 0.805 - ETA: 10s - loss: 0.5774 - accuracy: 0.805 - ETA: 10s - loss: 0.5770 - accuracy: 0.805 - ETA: 9s - loss: 0.5768 - accuracy: 0.805 - ETA: 9s - loss: 0.5766 - accuracy: 0.80 - ETA: 9s - loss: 0.5763 - accuracy: 0.80 - ETA: 9s - loss: 0.5761 - accuracy: 0.80 - ETA: 9s - loss: 0.5759 - accuracy: 0.80 - ETA: 9s - loss: 0.5755 - accuracy: 0.80 - ETA: 9s - loss: 0.5753 - accuracy: 0.80 - ETA: 9s - loss: 0.5749 - accuracy: 0.80 - ETA: 9s - loss: 0.5747 - accuracy: 0.80 - ETA: 8s - loss: 0.5742 - accuracy: 0.80 - ETA: 8s - loss: 0.5740 - accuracy: 0.80 - ETA: 8s - loss: 0.5737 - accuracy: 0.80 - ETA: 8s - loss: 0.5733 - accuracy: 0.80 - ETA: 8s - loss: 0.5730 - accuracy: 0.80 - ETA: 8s - loss: 0.5726 - accuracy: 0.80 - ETA: 8s - loss: 0.5724 - accuracy: 0.80 - ETA: 8s - loss: 0.5722 - accuracy: 0.80 - ETA: 8s - loss: 0.5719 - accuracy: 0.80 - ETA: 7s - loss: 0.5718 - accuracy: 0.80 - ETA: 7s - loss: 0.5716 - accuracy: 0.80 - ETA: 7s - loss: 0.5713 - accuracy: 0.80 - ETA: 7s - loss: 0.5711 - accuracy: 0.80 - ETA: 7s - loss: 0.5712 - accuracy: 0.80 - ETA: 7s - loss: 0.5709 - accuracy: 0.80 - ETA: 7s - loss: 0.5707 - accuracy: 0.80 - ETA: 7s - loss: 0.5705 - accuracy: 0.80 - ETA: 7s - loss: 0.5704 - accuracy: 0.80 - ETA: 7s - loss: 0.5702 - accuracy: 0.80 - ETA: 6s - loss: 0.5699 - accuracy: 0.80 - ETA: 6s - loss: 0.5696 - accuracy: 0.80 - ETA: 6s - loss: 0.5694 - accuracy: 0.80 - ETA: 6s - loss: 0.5691 - accuracy: 0.80 - ETA: 6s - loss: 0.5689 - accuracy: 0.80 - ETA: 6s - loss: 0.5686 - accuracy: 0.80 - ETA: 6s - loss: 0.5684 - accuracy: 0.80 - ETA: 6s - loss: 0.5681 - accuracy: 0.80 - ETA: 6s - loss: 0.5679 - accuracy: 0.80 - ETA: 5s - loss: 0.5676 - accuracy: 0.80 - ETA: 5s - loss: 0.5674 - accuracy: 0.80 - ETA: 5s - loss: 0.5673 - accuracy: 0.80 - ETA: 5s - loss: 0.5671 - accuracy: 0.80 - ETA: 5s - loss: 0.5667 - accuracy: 0.80 - ETA: 5s - loss: 0.5665 - accuracy: 0.80 - ETA: 5s - loss: 0.5662 - accuracy: 0.80 - ETA: 5s - loss: 0.5659 - accuracy: 0.80 - ETA: 5s - loss: 0.5659 - accuracy: 0.80 - ETA: 4s - loss: 0.5656 - accuracy: 0.80 - ETA: 4s - loss: 0.5655 - accuracy: 0.80 - ETA: 4s - loss: 0.5651 - accuracy: 0.80 - ETA: 4s - loss: 0.5649 - accuracy: 0.80 - ETA: 4s - loss: 0.5646 - accuracy: 0.80 - ETA: 4s - loss: 0.5644 - accuracy: 0.80 - ETA: 4s - loss: 0.5640 - accuracy: 0.80 - ETA: 4s - loss: 0.5637 - accuracy: 0.80 - ETA: 4s - loss: 0.5635 - accuracy: 0.80 - ETA: 3s - loss: 0.5632 - accuracy: 0.80 - ETA: 3s - loss: 0.5631 - accuracy: 0.80 - ETA: 3s - loss: 0.5633 - accuracy: 0.80 - ETA: 3s - loss: 0.5630 - accuracy: 0.80 - ETA: 3s - loss: 0.5626 - accuracy: 0.80 - ETA: 3s - loss: 0.5623 - accuracy: 0.80 - ETA: 3s - loss: 0.5621 - accuracy: 0.80 - ETA: 3s - loss: 0.5617 - accuracy: 0.80 - ETA: 3s - loss: 0.5615 - accuracy: 0.81 - ETA: 3s - loss: 0.5614 - accuracy: 0.81 - ETA: 2s - loss: 0.5611 - accuracy: 0.81 - ETA: 2s - loss: 0.5608 - accuracy: 0.81 - ETA: 2s - loss: 0.5607 - accuracy: 0.81 - ETA: 2s - loss: 0.5605 - accuracy: 0.81 - ETA: 2s - loss: 0.5604 - accuracy: 0.81 - ETA: 2s - loss: 0.5603 - accuracy: 0.81 - ETA: 2s - loss: 0.5601 - accuracy: 0.81 - ETA: 2s - loss: 0.5600 - accuracy: 0.81 - ETA: 2s - loss: 0.5598 - accuracy: 0.81 - ETA: 1s - loss: 0.5597 - accuracy: 0.81 - ETA: 1s - loss: 0.5594 - accuracy: 0.81 - ETA: 1s - loss: 0.5594 - accuracy: 0.81 - ETA: 1s - loss: 0.5592 - accuracy: 0.81 - ETA: 1s - loss: 0.5592 - accuracy: 0.81 - ETA: 1s - loss: 0.5590 - accuracy: 0.81 - ETA: 1s - loss: 0.5587 - accuracy: 0.81 - ETA: 1s - loss: 0.5584 - accuracy: 0.81 - ETA: 1s - loss: 0.5584 - accuracy: 0.81 - ETA: 0s - loss: 0.5581 - accuracy: 0.81 - ETA: 0s - loss: 0.5581 - accuracy: 0.81 - ETA: 0s - loss: 0.5580 - accuracy: 0.81 - ETA: 0s - loss: 0.5579 - accuracy: 0.81 - ETA: 0s - loss: 0.5577 - accuracy: 0.81 - ETA: 0s - loss: 0.5577 - accuracy: 0.8112"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.81 - ETA: 0s - loss: 0.5572 - accuracy: 0.81 - ETA: 0s - loss: 0.5569 - accuracy: 0.81 - ETA: 0s - loss: 0.5568 - accuracy: 0.81 - 106s 112ms/step - loss: 0.5568 - accuracy: 0.8115 - val_loss: 0.3865 - val_accuracy: 0.8675\n",
      "[Trial complete]\n",
      "[Trial summary]\n",
      " |-Trial ID: 0b3bc2017567893f0ddc171b83e1509a\n",
      " |-Score: 0.8675000071525574\n",
      " |-Best step: 0\n",
      " > Hyperparameters:\n",
      " |-conv_0_units: 128\n",
      " |-conv_1_units: 32\n",
      " |-input_units: 64\n",
      " |-n_layers: 2\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "        build_model_with_hp,\n",
    "        objective = 'val_accuracy',\n",
    "        max_trials = 1,\n",
    "        executions_per_trial = 1,\n",
    "        directory = loc_dir )\n",
    "\n",
    "tuner.search(x_train,y_train,\n",
    "            epochs=1,\n",
    "            batch_size = 64,\n",
    "            validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Results summary]\n",
      " |-Results in 1605197004\\untitled_project\n",
      " |-Showing 10 best trials\n",
      " |-Objective(name='val_accuracy', direction='max')\n",
      "[Trial summary]\n",
      " |-Trial ID: 0b3bc2017567893f0ddc171b83e1509a\n",
      " |-Score: 0.8675000071525574\n",
      " |-Best step: 0\n",
      " > Hyperparameters:\n",
      " |-conv_0_units: 128\n",
      " |-conv_1_units: 32\n",
      " |-input_units: 64\n",
      " |-n_layers: 2\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 9, 9, 32)          36896     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2592)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                25930     \n",
      "=================================================================\n",
      "Total params: 137,322\n",
      "Trainable params: 137,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "tuner.get_best_models()[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "y_pred=tuner.get_best_models()[0].predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.70286706e-04, 1.22055349e-06, 4.45961778e-05, 1.07840715e-04,\n",
       "       1.78468440e-06, 4.97533893e-03, 6.23587985e-05, 5.87099269e-02,\n",
       "       3.38005542e-04, 9.35188591e-01], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred=np.argmax(y_pred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[809,   5,  19,  33,   5,   1, 109,   0,  19,   0],\n",
       "       [  5, 972,   0,  14,   4,   0,   2,   0,   3,   0],\n",
       "       [ 13,   0, 766,   6, 129,   1,  83,   0,   2,   0],\n",
       "       [ 14,  33,  16, 832,  61,   0,  34,   0,  10,   0],\n",
       "       [  0,   0,  58,  19, 852,   0,  65,   0,   6,   0],\n",
       "       [  0,   0,   0,   0,   0, 965,   0,  17,   6,  12],\n",
       "       [127,   6,  90,  34, 119,   1, 597,   0,  26,   0],\n",
       "       [  0,   0,   0,   0,   0,  19,   0, 940,   1,  40],\n",
       "       [  2,   0,   3,   0,   4,   3,  15,   1, 972,   0],\n",
       "       [  0,   0,   0,   0,   0,   6,   0,  24,   0, 970]], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1000\n",
      "           1       0.96      0.97      0.96      1000\n",
      "           2       0.80      0.77      0.78      1000\n",
      "           3       0.89      0.83      0.86      1000\n",
      "           4       0.73      0.85      0.78      1000\n",
      "           5       0.97      0.96      0.97      1000\n",
      "           6       0.66      0.60      0.63      1000\n",
      "           7       0.96      0.94      0.95      1000\n",
      "           8       0.93      0.97      0.95      1000\n",
      "           9       0.95      0.97      0.96      1000\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It is showing nice results with keras tuner. Almost efficiency in 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
