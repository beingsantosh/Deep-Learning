{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hate Speech Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN7iNBB6OQysSGHB5ZK+OO4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santoshkumarbvp/Deep-Learning/blob/main/Hate_Speech_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTD9VhhwGXUY"
      },
      "source": [
        "Hate speech classification via deep learning\n",
        "\n",
        "  classes -\n",
        "   \n",
        "    hate speech\n",
        "\n",
        "    offensive language\n",
        "    \n",
        "    neither"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8JemOUr8VYQ"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2O3EiHYFHRN"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusertweet.com/laxmimerit/hate_speech_dataset/master/data.csv' , index_col=0)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3l9HMOIFSEx",
        "outputId": "86bb8b83-e7e9-47ca-c121-f45f44005dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   count  hate_speech  ...  class                                              tweet\n",
              "0      3            0  ...      2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
              "1      3            0  ...      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
              "2      3            0  ...      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
              "3      3            0  ...      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
              "4      6            0  ...      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4H_1mhRFSse",
        "outputId": "2cc98d5a-0ae8-4d80-be96-c62a802cf79b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vc=df['class'].value_counts()\n",
        "vc"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    19190\n",
              "2     4163\n",
              "0     1430\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfXfiQ4bG7Xv"
      },
      "source": [
        "This contains unbalanced classes. \n",
        "Will balance the complete dataset. \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x7317QmHFN5",
        "outputId": "7a49e3e0-1faf-4af5-ee64-405fd3a2e808",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df[df['class']==1].sample()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19190, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiV8WesiIwwg"
      },
      "source": [
        "index for min and max count "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxqbKPyiHT-t",
        "outputId": "7db8d8e8-5164-44f6-afc9-43796e532369",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vc[vc==vc.min()].index[0], vc[vc==vc.max()].index[0]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXoDhG_FHgw0",
        "outputId": "3e96ff7a-fea8-4761-9075-44c7ddcec4ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df[df['class']==vc[vc==vc.max()].index[0]].shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19190, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBq9ZhJyJFtx"
      },
      "source": [
        "just picking only 1430 samples from class 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yPcFyKNI-g9"
      },
      "source": [
        "df_new = pd.DataFrame()\n",
        "\n",
        "for i in vc.index:\n",
        "  temp = df[df['class']==i].sample(vc.min())\n",
        "  df_new = df_new.append(temp,ignore_index = True)  "
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5qyjhRQJW5K",
        "outputId": "995acd5e-1482-4b05-edbc-721e500fd992",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_new.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4290, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVJ89SreJ9DS",
        "outputId": "16848089-103d-46ab-c00d-ec0b614af571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n",
        "def contraction_(x):\n",
        "    for cont , exp in contraction_mapping.items():\n",
        "        x = re.sub(cont,exp,x)\n",
        "    return x\n",
        "\n",
        "import unicodedata\n",
        "def remove_accented_chars(x):\n",
        "    x = unicodedata.normalize('NFKD', x).encode('ascii','ignore').decode('utf-8','ignore')\n",
        "    return x\n",
        "\n",
        "#email\n",
        "regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
        "\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def convert_to_root(x):\n",
        "    doc= nlp(x)\n",
        "    x_list=[]\n",
        "    for w in doc:\n",
        "        root = w.lemma_\n",
        "        x_list.append(root)\n",
        "    return ' '.join(x_list)\n",
        "\n",
        "\n",
        "df_new['tweet']=df_new['tweet'].apply(lambda x: x.lower() )\n",
        "df_new['tweet']=df_new['tweet'].apply(lambda x: contraction_(x))\n",
        "df_new['tweet']=df_new['tweet'].apply(lambda x : re.sub('[a-zA-Z0-9_-]*@[a-zA-Z0-9_-]+\\.com',' ', x))\n",
        "df_new['tweet']=df_new['tweet'].apply(lambda x : re.sub(regex, '', x))\n",
        "df_new['tweet']=df_new['tweet'].apply(lambda x : re.sub('[^\\w ]+','',x))\n",
        "df_new['tweet']=df_new['tweet'].apply(lambda x : re.sub('\\s{2,}',' ',x))\n",
        "df_new['tweet']=df_new['tweet'].apply(lambda x : BeautifulSoup(x,'html').get_text().strip())\n",
        "df_new['tweet']=df_new['tweet'].apply(lambda x : remove_accented_chars(x))\n",
        "df_new['tweet']=df_new['tweet'].apply(lambda x : ' '.join([w for w in x.split() if w not in stopwords]))\n",
        "df_new['tweet']=df_new['tweet'].apply(lambda x : convert_to_root(x))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 40.2 s, sys: 164 ms, total: 40.4 s\n",
            "Wall time: 40.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mfJNFELK2B0",
        "outputId": "cd8fc37b-009b-4b96-eb74-0b5e847e0c9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "df_new"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>ray rice bitch xans lean punch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>bad bitch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1000gramsbee bitch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>rt fredosantana300 bitch forget hit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>act like little booshie bitch friend hoe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4285</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>maliktender gayer 2 faggot bed together128129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4286</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ok bitch wut think shesaid believe u describe ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4287</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>rt lady_blahblah furrybah paypay voice rt 80sb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4288</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>scandal negro bed wenchs fairytale propaganda ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4289</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>chasebasford chase god damn faggot 12851412855...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4290 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      count  ...                                              tweet\n",
              "0         3  ...                     ray rice bitch xans lean punch\n",
              "1         3  ...                                          bad bitch\n",
              "2         3  ...                                 1000gramsbee bitch\n",
              "3         3  ...                rt fredosantana300 bitch forget hit\n",
              "4         3  ...           act like little booshie bitch friend hoe\n",
              "...     ...  ...                                                ...\n",
              "4285      3  ...      maliktender gayer 2 faggot bed together128129\n",
              "4286      3  ...  ok bitch wut think shesaid believe u describe ...\n",
              "4287      3  ...  rt lady_blahblah furrybah paypay voice rt 80sb...\n",
              "4288      3  ...  scandal negro bed wenchs fairytale propaganda ...\n",
              "4289      3  ...  chasebasford chase god damn faggot 12851412855...\n",
              "\n",
              "[4290 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4npnBjeFLoEI"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Embedding, Dropout, Conv1D, MaxPool1D, GlobalAveragePooling1D\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_ceX_NoMbBJ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_Zb1FZSMmbc"
      },
      "source": [
        "Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67jkGPqHMowT"
      },
      "source": [
        "text = df_new['tweet'].tolist()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haKQPrwdMu3u",
        "outputId": "c15702fd-d35a-4d1b-f0af-7b0542ff66f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text[:2]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ray rice bitch xans lean punch', 'bad bitch']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFkdWlxfMyFB"
      },
      "source": [
        "token = Tokenizer()\n",
        "token.fit_on_texts(text)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ2W3-oYNBXI",
        "outputId": "7532aa1e-0e96-42c1-9693-d2e567050acc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "token."
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-aa3468881000>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSadKLrGNHR9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}